{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лабораторная работа №2. Реализация глубокой нейронной сети**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Данные:** В работе предлагается использовать набор данных notMNIST, который состоит из изображений размерностью 28×28 первых 10 букв латинского алфавита (A … J, соответственно). Обучающая выборка содержит порядка 500 тыс. изображений, а тестовая – около 19 тыс.\n",
    "\n",
    "Данные можно скачать по ссылке:\n",
    "\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_large.tar.gz (большой набор данных);\n",
    "\n",
    "https://commondatastorage.googleapis.com/books1000/notMNIST_small.tar.gz (маленький набор данных);\n",
    "\n",
    "Описание данных на английском языке доступно по ссылке:\n",
    "http://yaroslavvb.blogspot.sg/2011/09/notmnist-dataset.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import savemat\n",
    "import numpy, glob, sys, os\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(folder, target):\n",
    "    max_count = 0\n",
    "    for (root, dirs, files) in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.endswith('.png'):\n",
    "                max_count += 1\n",
    "    print('Found %s files' % (max_count,))\n",
    "    data = numpy.zeros((28,28,max_count))\n",
    "    labels = numpy.zeros((max_count,))\n",
    "    count = 0\n",
    "    for (root, dirs, files) in os.walk(folder):\n",
    "        for f in files:\n",
    "            if f.endswith('.png'):\n",
    "                try:\n",
    "                    img = Image.open(os.path.join(root,f));\n",
    "                    data[:,:,count]=numpy.asarray(img)\n",
    "                    surround_folder = os.path.split(root)[-1]\n",
    "                    assert len(surround_folder)==1\n",
    "                    labels[count]=ord(surround_folder)-ord('A')\n",
    "                    count+=1\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "    print('Saving to ', target)\n",
    "    savemat(target,{'images': data[:,:,:count],'labels': labels[:count]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 18726 files\n",
      "Saving to  test_dataset.mat\n",
      "Found 529119 files\n",
      "Saving to  train_dataset.mat\n"
     ]
    }
   ],
   "source": [
    "generateDataset(\"notMNIST_small\", \"test_dataset.mat\")\n",
    "generateDataset(\"notMNIST_large\", \"train_dataset.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(529115, 28, 28) (529115, 1)\n",
      "(18724, 28, 28) (18724, 1)\n"
     ]
    }
   ],
   "source": [
    "def getDataset(file):\n",
    "    matfile = loadmat(file)\n",
    "    x = matfile['images'] / 255\n",
    "    y = matfile['labels']\n",
    "    return x.T, y.T\n",
    "    \n",
    "trainX, trainY = getDataset('train_dataset.mat')\n",
    "print(trainX.shape, trainY.shape)\n",
    "\n",
    "testX, testY = getDataset('test_dataset.mat')\n",
    "print(testX.shape, testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.\n",
    "Р**еализуйте полносвязную нейронную сеть с помощью библиотеки Tensor Flow. В качестве алгоритма оптимизации можно использовать, например, стохастический градиент (Stochastic Gradient Descent, SGD). Определите количество скрытых слоев от 1 до 5, количество нейронов в каждом из слоев до нескольких сотен, а также их функции активации (кусочно-линейная, сигмоидная, гиперболический тангенс и т.д.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/alinadolmatovich/anaconda2/envs/tensorflow-env/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Train on 529115 samples\n",
      "Epoch 1/15\n",
      "529115/529115 [==============================] - 199s 375us/sample - loss: 0.4140 - acc: 0.8734\n",
      "Epoch 2/15\n",
      "529115/529115 [==============================] - 192s 362us/sample - loss: 0.3290 - acc: 0.8979\n",
      "Epoch 3/15\n",
      "529115/529115 [==============================] - 190s 360us/sample - loss: 0.3008 - acc: 0.9061\n",
      "Epoch 4/15\n",
      "529115/529115 [==============================] - 185s 349us/sample - loss: 0.2836 - acc: 0.9110\n",
      "Epoch 5/15\n",
      "529115/529115 [==============================] - 178s 337us/sample - loss: 0.2704 - acc: 0.9148\n",
      "Epoch 6/15\n",
      "529115/529115 [==============================] - 179s 338us/sample - loss: 0.2609 - acc: 0.9177\n",
      "Epoch 7/15\n",
      "529115/529115 [==============================] - 174s 328us/sample - loss: 0.2534 - acc: 0.9199\n",
      "Epoch 8/15\n",
      "529115/529115 [==============================] - 181s 342us/sample - loss: 0.2470 - acc: 0.9218\n",
      "Epoch 9/15\n",
      "529115/529115 [==============================] - 168s 318us/sample - loss: 0.2403 - acc: 0.9236\n",
      "Epoch 10/15\n",
      "529115/529115 [==============================] - 191s 362us/sample - loss: 0.2366 - acc: 0.9248\n",
      "Epoch 11/15\n",
      "529115/529115 [==============================] - 202s 382us/sample - loss: 0.2324 - acc: 0.9259\n",
      "Epoch 12/15\n",
      "529115/529115 [==============================] - 179s 337us/sample - loss: 0.2280 - acc: 0.9273\n",
      "Epoch 13/15\n",
      "529115/529115 [==============================] - 187s 353us/sample - loss: 0.2246 - acc: 0.9287\n",
      "Epoch 14/15\n",
      "529115/529115 [==============================] - 188s 356us/sample - loss: 0.2213 - acc: 0.9293\n",
      "Epoch 15/15\n",
      "529115/529115 [==============================] - 181s 342us/sample - loss: 0.2184 - acc: 0.9304\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13face4a8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.**\n",
    "Как улучшилась точность классификатора по сравнению с логистической регрессией?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18724/18724 - 2s - loss: 0.1378 - acc: 0.9621\n",
      "Точность на проверочных данных: 0.9621342\n"
     ]
    }
   ],
   "source": [
    "testLoss, testAcc = model.evaluate(testX,  testY, verbose=2)\n",
    "print('Точность на проверочных данных:', testAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.**\n",
    "Используйте регуляризацию и метод сброса нейронов (dropout) для борьбы с переобучением. Как улучшилось качество классификации?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 529115 samples\n",
      "Epoch 1/15\n",
      "529115/529115 [==============================] - 251s 475us/sample - loss: 0.6194 - acc: 0.8538\n",
      "Epoch 2/15\n",
      "529115/529115 [==============================] - 264s 499us/sample - loss: 0.5291 - acc: 0.8673\n",
      "Epoch 3/15\n",
      "529115/529115 [==============================] - 295s 558us/sample - loss: 0.5174 - acc: 0.8694\n",
      "Epoch 4/15\n",
      "529115/529115 [==============================] - 306s 579us/sample - loss: 0.5108 - acc: 0.8707\n",
      "Epoch 5/15\n",
      "529115/529115 [==============================] - 291s 550us/sample - loss: 0.5062 - acc: 0.8709\n",
      "Epoch 6/15\n",
      "529115/529115 [==============================] - 312s 589us/sample - loss: 0.5040 - acc: 0.8715\n",
      "Epoch 7/15\n",
      "529115/529115 [==============================] - 295s 557us/sample - loss: 0.5038 - acc: 0.8713\n",
      "Epoch 8/15\n",
      "529115/529115 [==============================] - 283s 536us/sample - loss: 0.5027 - acc: 0.8714\n",
      "Epoch 9/15\n",
      "529115/529115 [==============================] - 244s 460us/sample - loss: 0.5017 - acc: 0.8715\n",
      "Epoch 10/15\n",
      "529115/529115 [==============================] - 239s 452us/sample - loss: 0.4999 - acc: 0.8710\n",
      "Epoch 11/15\n",
      "529115/529115 [==============================] - 244s 461us/sample - loss: 0.4994 - acc: 0.8715\n",
      "Epoch 12/15\n",
      "529115/529115 [==============================] - 239s 451us/sample - loss: 0.4991 - acc: 0.8710\n",
      "Epoch 13/15\n",
      "529115/529115 [==============================] - 243s 459us/sample - loss: 0.4976 - acc: 0.8716\n",
      "Epoch 14/15\n",
      "529115/529115 [==============================] - 251s 475us/sample - loss: 0.4980 - acc: 0.8716\n",
      "Epoch 15/15\n",
      "529115/529115 [==============================] - 249s 470us/sample - loss: 0.4981 - acc: 0.8712\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x65c8dde10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regularizationModel = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'),\n",
    "    keras.layers.Dense(128, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'),\n",
    "    keras.layers.Dense(64, kernel_regularizer=keras.regularizers.l2(0.001), activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "regularizationModel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "regularizationModel.fit(trainX, trainY, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18724/18724 - 3s - loss: 0.3101 - acc: 0.9301\n",
      "Точность на проверочных данных c регуляризацией: 0.9300897\n"
     ]
    }
   ],
   "source": [
    "testRegularizationLoss, testRegularizationAcc = regularizationModel.evaluate(testX,  testY, verbose=2)\n",
    "print('Точность на проверочных данных c регуляризацией:', testRegularizationAcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 529115 samples\n",
      "Epoch 1/15\n",
      "529115/529115 [==============================] - 284s 536us/sample - loss: 0.7617 - acc: 0.7801\n",
      "Epoch 2/15\n",
      "529115/529115 [==============================] - 284s 537us/sample - loss: 0.6313 - acc: 0.8222\n",
      "Epoch 3/15\n",
      "529115/529115 [==============================] - 280s 529us/sample - loss: 0.6077 - acc: 0.8285\n",
      "Epoch 4/15\n",
      "529115/529115 [==============================] - 280s 529us/sample - loss: 0.5949 - acc: 0.8326\n",
      "Epoch 5/15\n",
      "529115/529115 [==============================] - 287s 542us/sample - loss: 0.5863 - acc: 0.8340\n",
      "Epoch 6/15\n",
      "529115/529115 [==============================] - 279s 527us/sample - loss: 0.5816 - acc: 0.8358\n",
      "Epoch 7/15\n",
      "529115/529115 [==============================] - 306s 579us/sample - loss: 0.5772 - acc: 0.8367\n",
      "Epoch 8/15\n",
      "529115/529115 [==============================] - 284s 537us/sample - loss: 0.5737 - acc: 0.8382\n",
      "Epoch 9/15\n",
      "529115/529115 [==============================] - 314s 593us/sample - loss: 0.5706 - acc: 0.8389\n",
      "Epoch 10/15\n",
      "529115/529115 [==============================] - 365s 691us/sample - loss: 0.5695 - acc: 0.8391\n",
      "Epoch 11/15\n",
      "529115/529115 [==============================] - 381s 720us/sample - loss: 0.5662 - acc: 0.8403\n",
      "Epoch 12/15\n",
      "529115/529115 [==============================] - 435s 822us/sample - loss: 0.5639 - acc: 0.8414- lo\n",
      "Epoch 13/15\n",
      "529115/529115 [==============================] - 406s 767us/sample - loss: 0.5646 - acc: 0.8411\n",
      "Epoch 14/15\n",
      "529115/529115 [==============================] - 325s 615us/sample - loss: 0.5609 - acc: 0.8420\n",
      "Epoch 15/15\n",
      "529115/529115 [==============================] - 344s 650us/sample - loss: 0.5606 - acc: 0.8418\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x65c884fd0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropoutModel = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "dropoutModel.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "dropoutModel.fit(trainX, trainY, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18724/18724 - 4s - loss: 0.2280 - acc: 0.9383\n",
      "Точность на проверочных данных c dropout'ом: 0.93826103\n"
     ]
    }
   ],
   "source": [
    "testDropoutLoss, testDropoutAcc = dropoutModel.evaluate(testX,  testY, verbose=2)\n",
    "print('Точность на проверочных данных c dropout\\'ом:', testDropoutAcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4.**\n",
    "Воспользуйтесь динамически изменяемой скоростью обучения (learning rate). Наилучшая точность, достигнутая с помощью данной модели составляет 97.1%. Какую точность демонстрирует Ваша реализованная модель?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 529115 samples\n",
      "Epoch 1/15\n",
      "529115/529115 [==============================] - 238s 450us/sample - loss: 0.5622 - acc: 0.8365\n",
      "Epoch 2/15\n",
      "529115/529115 [==============================] - 227s 429us/sample - loss: 0.5079 - acc: 0.8517\n",
      "Epoch 3/15\n",
      "529115/529115 [==============================] - 211s 398us/sample - loss: 0.4919 - acc: 0.8560\n",
      "Epoch 4/15\n",
      "529115/529115 [==============================] - 216s 408us/sample - loss: 0.4838 - acc: 0.8582\n",
      "Epoch 5/15\n",
      "529115/529115 [==============================] - 226s 426us/sample - loss: 0.4795 - acc: 0.8593\n",
      "Epoch 6/15\n",
      "529115/529115 [==============================] - 225s 425us/sample - loss: 0.4743 - acc: 0.8611\n",
      "Epoch 7/15\n",
      "529115/529115 [==============================] - 268s 506us/sample - loss: 0.4696 - acc: 0.8624\n",
      "Epoch 8/15\n",
      "529115/529115 [==============================] - 246s 464us/sample - loss: 0.4654 - acc: 0.8628\n",
      "Epoch 9/15\n",
      "529115/529115 [==============================] - 221s 418us/sample - loss: 0.4641 - acc: 0.8621\n",
      "Epoch 10/15\n",
      "529115/529115 [==============================] - 249s 471us/sample - loss: 0.4596 - acc: 0.8641\n",
      "Epoch 11/15\n",
      "529115/529115 [==============================] - 254s 480us/sample - loss: 0.4609 - acc: 0.8635\n",
      "Epoch 12/15\n",
      "529115/529115 [==============================] - 243s 459us/sample - loss: 0.4555 - acc: 0.8657\n",
      "Epoch 13/15\n",
      "529115/529115 [==============================] - 238s 449us/sample - loss: 0.4509 - acc: 0.8673\n",
      "Epoch 14/15\n",
      "529115/529115 [==============================] - 281s 531us/sample - loss: 0.4529 - acc: 0.8657\n",
      "Epoch 15/15\n",
      "529115/529115 [==============================] - 250s 473us/sample - loss: 0.4518 - acc: 0.8658\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x652009e10>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "adamOptimizer = keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(optimizer=adamOptimizer,\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(trainX, trainY, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18724/18724 - 4s - loss: 0.2816 - acc: 0.9214\n",
      "Точность на проверочных данных c learning rate оптимизацией: 0.92138433\n"
     ]
    }
   ],
   "source": [
    "testDropoutLoss, testDropoutAcc = model.evaluate(testX,  testY, verbose=2)\n",
    "print('Точность на проверочных данных c learning rate оптимизацией:', testDropoutAcc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
